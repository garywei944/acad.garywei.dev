@inproceedings{wei2024navigating,
  abbr              = {AI4Science Spotlight},
  title             = {Navigating Chemical Space with Latent Flows},
  author            = {Guanghao Wei* and Yining Huang* and Chenru Duan and Yue Song† and Yuanqi Du†},
  year              = {2024},
  booktitle         = {ICML 2024 AI for Science Workshop},
  archiveprefix     = {arXiv},
  eprint            = {2405.03987},
  primaryclass      = {cs.LG},
  arxiv             = {2405.03987},
  doi               = {10.48550/arXiv.2405.03987},
  url               = {https://openreview.net/forum?id=fHRwmeHOpc},
  pdf               = {https://arxiv.org/pdf/2405.03987},
  code              = {https://github.com/garywei944/ChemFlow},
  poster            = {https://s3.amazonaws.com/garywei.dev/public/projects/chemflow/ChemFlow_Poster.pdf},
  supp              = {https://colab.research.google.com/drive/1QAy_QoEnDRaiLF6kJ6RyhuGx1qCJXYKm?usp=sharing},
  google_scholar_id = {2osOgNQ5qMEC},
  preview           = {wei2024navigating.png},
  bibtex_show       = {true},
  altmetric         = {true},
  abstract          = {Recent progress of deep generative models in the vision and language domain has stimulated significant interest in more structured data generation such as molecules. However, beyond generating new random molecules, efficient exploration and a comprehensive understanding of the vast chemical space are of great importance to molecular science and applications in drug design and materials discovery. In this paper, we propose a new framework, ChemFlow, to traverse chemical space through navigating the latent space learned by molecule generative models through flows. We introduce a dynamical system perspective that formulates the problem as learning a vector field that transports the mass of the molecular distribution to the region with desired molecular properties or structure diversity. Under this framework, we unify previous approaches on molecule latent space traversal and optimization and propose alternative competing methods incorporating different physical priors. We validate the efficacy of ChemFlow on molecule manipulation and single- and multi-objective molecule optimization tasks under both supervised and unsupervised molecular discovery settings. Codes and demos are publicly available on GitHub at https://github.com/garywei944/ChemFlow.},
  selected          = {true}
}
@misc{yao2023readme,
  title             = {README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP},
  author            = {Zonghai Yao and Nandyala Siddharth Kantu and Guanghao Wei and Hieu Tran and Zhangqi Duan and Sunjae Kwon and Zhichao Yang and README annotation team and Hong Yu},
  year              = {2023},
  eprint            = {2312.15561},
  archiveprefix     = {arXiv},
  primaryclass      = {cs.CL},
  arxiv             = {2312.15561},
  doi               = {10.48550/arXiv.2312.15561},
  pdf               = {https://arxiv.org/pdf/2312.15561.pdf},
  code              = {https://github.com/seasonyao/NoteAid-README},
  google_scholar_id = {9yKSN-GCB0IC},
  preview           = {yao2023readme.jpg},
  bibtex_show       = {true},
  altmetric         = {true},
  abstract          = {The advancement in healthcare has shifted focus toward patient-centric approaches, particularly in self-care and patient education, facilitated by access to Electronic Health Records (EHR). However, medical jargon in EHRs poses significant challenges in patient comprehension. To address this, we introduce a new task of automatically generating lay definitions, aiming to simplify complex medical terms into patient-friendly lay language. We first created the README dataset, an extensive collection of over 50,000 unique (medical term, lay definition) pairs and 300,000 mentions, each offering context-aware lay definitions manually annotated by domain experts. We have also engineered a data-centric Human-AI pipeline that synergizes data filtering, augmentation, and selection to improve data quality. We then used README as the training data for models and leveraged a Retrieval-Augmented Generation method to reduce hallucinations and improve the quality of model outputs. Our extensive automatic and human evaluations demonstrate that open-source mobile-friendly models, when fine-tuned with high-quality data, are capable of matching or even surpassing the performance of state-of-the-art closed-source large language models like ChatGPT. This research represents a significant stride in closing the knowledge gap in patient education and advancing patient-centric healthcare solutions.}
}
@misc{wei2023grabsampler,
  title             = {GraB-sampler: Optimal Permutation-based SGD Data Sampler for PyTorch},
  author            = {Guanghao Wei},
  year              = {2023},
  eprint            = {2309.16809},
  archiveprefix     = {arXiv},
  primaryclass      = {cs.LG},
  arxiv             = {2309.16809},
  doi               = {10.48550/arXiv.2309.16809},
  pdf               = {https://arxiv.org/pdf/2309.16809},
  code              = {https://github.com/garywei944/grab-sampler},
  website           = {https://pypi.org/project/grab-sampler/},
  google_scholar_id = {d1gkVwhDpl0C},
  preview           = {wei2023grabsampler.jpg},
  bibtex_show       = {true},
  altmetric         = {true},
  abstract          = {The online Gradient Balancing (GraB) algorithm greedily choosing the examples ordering by solving the herding problem using per-sample gradients is proved to be the theoretically optimal solution that guarantees to outperform Random Reshuffling. However, there is currently no efficient implementation of GraB for the community to easily use it. <br><br> This work presents an efficient Python library, GraB-sampler, that allows the community to easily use GraB algorithms and proposes 5 variants of the GraB algorithm. The best performance result of the GraB-sampler reproduces the training loss and test accuracy results while only in the cost of 8.7% training time overhead and 0.85% peak GPU memory usage overhead.},
  selected          = {true}
}
@misc{li2023gpu,
  title             = {GPU Scheduler for De Novo Genome Assembly with Multiple MPI Processes},
  author            = {Guanghao Wei* and Minhao Li* and Siyu Wang*},
  year              = {2023},
  eprint            = {2309.07270},
  archiveprefix     = {arXiv},
  primaryclass      = {cs.DC},
  arxiv             = {2309.07270},
  doi               = {10.48550/arXiv.2309.07270},
  pdf               = {https://arxiv.org/pdf/2309.07270.pdf},
  code              = {https://github.com/garywei944/ELBA/tree/GPU},
  poster            = {https://s3.amazonaws.com/garywei.dev/public/posters/ELBA+GPU+poster.pdf},
  google_scholar_id = {u-x6o8ySG0sC},
  preview           = {li2023gpu.jpg},
  bibtex_show       = {true},
  altmetric         = {true},
  abstract          = {<i>De Novo</i> Genome assembly is one of the most important tasks in computational biology. ELBA is the state-of-the-art distributed-memory parallel algorithm for overlap detection and layout simplification steps of D<i>De Novo</i> genome assembly but exists a performance bottleneck in pairwise alignment. <br><br> In this work, we proposed 3 GPU schedulers for ELBA to accommodate multiple MPI processes and multiple GPUs. The GPU schedulers enable multiple MPI processes to perform computation on GPUs in a round-robin fashion. Both strong and weak scaling experiments show that 3 schedulers are able to significantly improve the performance of baseline while there is a trade-off between parallelism and GPU scheduler overhead. For the best performance implementation, the one-to-one scheduler achieves ∼7-8× speed-up using 25 MPI processes compared with the baseline vanilla ELBA GPU scheduler.}
}
